{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apchavezr/-Analisis_Grandes_Volumenes_Datos/blob/main/actividad_pyspark_distribuido.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3f6226",
      "metadata": {
        "id": "9b3f6226"
      },
      "source": [
        "# ðŸ§ª Actividad prÃ¡ctica: Procesamiento distribuido con PySpark en Jupyter Notebook\n",
        "\n",
        "**Objetivo:** Simular un entorno de procesamiento distribuido y realizar operaciones bÃ¡sicas con PySpark para comprender el modelo de ejecuciÃ³n distribuido de Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "326f4e9a",
      "metadata": {
        "id": "326f4e9a"
      },
      "source": [
        "### âœ… Requisitos previos\n",
        "Ejecute en consola:\n",
        "```bash\n",
        "pip install pyspark findspark jupyterlab\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark findspark jupyterlab"
      ],
      "metadata": {
        "id": "-q0P2A9vrgzg"
      },
      "id": "-q0P2A9vrgzg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4ffe83d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "4ffe83d3",
        "outputId": "aeea792a-8d7d-4795-bf9c-68389a33b3e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7871bcb4d690>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://906891f8e233:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>EjemploProcesamientoDistribuido</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"EjemploProcesamientoDistribuido\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a5a85388",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5a85388",
        "outputId": "3aa75b82-ced4-46b4-82b6-e04877f4e4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------------+\n",
            "|nombre|edad|      ciudad|\n",
            "+------+----+------------+\n",
            "|  Juan|  34|      BogotÃ¡|\n",
            "|   Ana|  29|    MedellÃ­n|\n",
            "|Carlos|  40|        Cali|\n",
            "| Luisa|  31|Barranquilla|\n",
            "+------+----+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "datos = [\n",
        "    Row(nombre=\"Juan\", edad=34, ciudad=\"BogotÃ¡\"),\n",
        "    Row(nombre=\"Ana\", edad=29, ciudad=\"MedellÃ­n\"),\n",
        "    Row(nombre=\"Carlos\", edad=40, ciudad=\"Cali\"),\n",
        "    Row(nombre=\"Luisa\", edad=31, ciudad=\"Barranquilla\")\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(datos)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "608e11a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "608e11a3",
        "outputId": "146fddf9-edc2-44c8-d4c9-663671ee2397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------------+\n",
            "|nombre|edad|      ciudad|\n",
            "+------+----+------------+\n",
            "|  Juan|  34|      BogotÃ¡|\n",
            "|Carlos|  40|        Cali|\n",
            "| Luisa|  31|Barranquilla|\n",
            "+------+----+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Filtrar personas mayores de 30 aÃ±os\n",
        "df_filtrado = df.filter(df[\"edad\"] > 30)\n",
        "df_filtrado.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a9f0410f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9f0410f",
        "outputId": "e52b6298-838f-4dd8-ce9f-6796e026190e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|avg(edad)|\n",
            "+---------+\n",
            "|     33.5|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calcular edad promedio\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "df.select(avg(\"edad\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "077a3f4e",
      "metadata": {
        "id": "077a3f4e"
      },
      "outputs": [],
      "source": [
        "# Guardar en formato CSV local\n",
        "df_filtrado.write.csv(\"salida_filtrada.csv\", header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9e9a6eff",
      "metadata": {
        "id": "9e9a6eff"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "817c546f",
      "metadata": {
        "id": "817c546f"
      },
      "source": [
        "### ðŸ§  Actividad de reflexiÃ³n\n",
        "\n",
        "> Â¿CÃ³mo cambiarÃ­a este procesamiento si se ejecutara sobre un clÃºster real con mÃºltiples nodos? Â¿QuÃ© ventajas adicionales se obtendrÃ­an en escalabilidad y rendimiento?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}