{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apchavezr/-Analisis_Grandes_Volumenes_Datos/blob/main/Comparacion_MapReduce_vs_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e2e1ea0",
      "metadata": {
        "id": "8e2e1ea0"
      },
      "source": [
        "# Comparación de latencia entre MapReduce y Spark\n",
        "\n",
        "Este cuaderno permite comparar la ejecución de un mismo algoritmo (conteo de palabras) usando una simulación del modelo MapReduce en Python y PySpark. Se observarán diferencias en latencia y modelo de procesamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f32642d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f32642d4",
        "outputId": "2d6cdf1e-b5c9-4ce1-ba7b-f1d65b66e887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Instalación de PySpark en el entorno (solo necesario una vez)\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8f3f19b9",
      "metadata": {
        "id": "8f3f19b9"
      },
      "outputs": [],
      "source": [
        "# Se crea una sesión de Spark y el contexto de SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "import time\n",
        "\n",
        "# Se crea una sesión de Spark y el contexto de SparkContext\n",
        "spark = SparkSession.builder.appName(\"ComparacionMapReduceSpark\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a06fd50",
      "metadata": {
        "id": "9a06fd50"
      },
      "source": [
        "## Paso 1: Simulación del algoritmo MapReduce en Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6034fb87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6034fb87",
        "outputId": "b8f0a216-4a0b-4d5a-9340-dd0c02ea4f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado MapReduce (Python):\n",
            "big: 3\n",
            "data: 2\n",
            "requiere: 1\n",
            "procesamiento: 1\n",
            "distribuido: 1\n",
            "y: 1\n",
            "spark: 2\n",
            "acelera: 1\n",
            "procesos: 1\n",
            "Tiempo de ejecución MapReduce simulado: 0.000182 segundos\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Texto de ejemplo que será procesado con ambos modelos\n",
        "texto = \"big data requiere procesamiento distribuido y spark acelera procesos big data big spark\"\n",
        "\n",
        "# Se inicia el conteo de tiempo para medir la latencia del modelo\n",
        "inicio_mapreduce = time.time()\n",
        "\n",
        "# Map\n",
        "# Fase Map: convierte cada palabra en una tupla (palabra, 1)\n",
        "map_output = [(palabra, 1) for palabra in texto.split()]\n",
        "\n",
        "# Reduce\n",
        "# Fase Reduce: acumula las ocurrencias de cada palabra\n",
        "reduce_output = defaultdict(int)\n",
        "for palabra, cuenta in map_output:\n",
        "# Fase Reduce: acumula las ocurrencias de cada palabra\n",
        "    reduce_output[palabra] += cuenta\n",
        "\n",
        "fin_mapreduce = time.time()\n",
        "\n",
        "# Se imprime el resultado y el tiempo de ejecución\n",
        "print(\"Resultado MapReduce (Python):\")\n",
        "# Fase Reduce: acumula las ocurrencias de cada palabra\n",
        "for palabra, cuenta in reduce_output.items():\n",
        "# Se imprime el resultado y el tiempo de ejecución\n",
        "    print(f\"{palabra}: {cuenta}\")\n",
        "\n",
        "# Se inicia el conteo de tiempo para medir la latencia del modelo\n",
        "print(f\"Tiempo de ejecución MapReduce simulado: {fin_mapreduce - inicio_mapreduce:.6f} segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f63f33c",
      "metadata": {
        "id": "2f63f33c"
      },
      "source": [
        "## Paso 2: Implementación del mismo algoritmo con PySpark (RDD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3090d5d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3090d5d8",
        "outputId": "5dde02ac-5575-41e9-9516-0319c7d5f2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado PySpark RDD:\n",
            "big: 3\n",
            "requiere: 1\n",
            "procesamiento: 1\n",
            "distribuido: 1\n",
            "data: 2\n",
            "y: 1\n",
            "spark: 2\n",
            "acelera: 1\n",
            "procesos: 1\n",
            "Tiempo de ejecución PySpark: 4.067306 segundos\n"
          ]
        }
      ],
      "source": [
        "# Se inicia el conteo de tiempo para medir la latencia del modelo\n",
        "inicio_spark = time.time()\n",
        "\n",
        "# Se paraleliza el texto dividiéndolo en palabras con Spark\n",
        "palabras = sc.parallelize(texto.split())\n",
        "# Fase Map y Reduce usando PySpark con RDDs\n",
        "conteo = palabras.map(lambda x: (x, 1)).reduceByKey(lambda a, b: a + b)\n",
        "# Se recopilan los resultados distribuidos al driver\n",
        "resultado = conteo.collect()\n",
        "\n",
        "fin_spark = time.time()\n",
        "\n",
        "# Se imprime el resultado y el tiempo de ejecución\n",
        "print(\"Resultado PySpark RDD:\")\n",
        "for palabra, cuenta in resultado:\n",
        "# Se imprime el resultado y el tiempo de ejecución\n",
        "    print(f\"{palabra}: {cuenta}\")\n",
        "\n",
        "# Se inicia el conteo de tiempo para medir la latencia del modelo\n",
        "print(f\"Tiempo de ejecución PySpark: {fin_spark - inicio_spark:.6f} segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d72a91a",
      "metadata": {
        "id": "8d72a91a"
      },
      "source": [
        "## Paso 3: Comparación de resultados y explicación"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3592f05e",
      "metadata": {
        "id": "3592f05e"
      },
      "source": [
        "- **MapReduce en Python** ejecuta el procesamiento de forma secuencial, con uso intensivo de lectura y escritura en memoria local.\n",
        "- **PySpark RDD** permite ejecutar el mismo algoritmo en paralelo, distribuyendo las operaciones entre los nodos virtuales del motor Spark.\n",
        "- Aunque en este entorno la diferencia de tiempo puede no ser significativa, en volúmenes de datos mayores Spark ofrece ventajas claras en latencia al usar procesamiento en memoria.\n",
        "\n",
        "### Reflexión:\n",
        "- ¿Qué cambios observa si repite el ejercicio con un texto 100 veces más largo?\n",
        "- ¿Qué ventajas tiene el modelo in-memory de Spark frente al modelo secuencial?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}